{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad520ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##Mohsin\n",
    "#Assignment 12 Glass \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# Load data\n",
    "data = pd.read_csv(\"glass.csv\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2acfb7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ff8cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac721a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf73886",
   "metadata": {},
   "source": [
    "From the statistical summary, we can observe the following insights:\n",
    "\n",
    "The dataset contains 214 samples/observations.\n",
    "The mean value of RI (refractive index) is around 1.52.\n",
    "The mean value of Ca (calcium) is the highest among all the features.\n",
    "The standard deviation (std) is high for K (potassium), Ca, and Ba (barium) features.\n",
    "The minimum and maximum values for each feature are also listed, which gives an idea of the range of values the features can take.\n",
    "The quartiles (25%, 50%, and 75%) give an idea about the distribution of the values. For example, the median value (50%) of RI is 1.51768, which indicates that half of the observations have RI less than 1.51768, and the other half have RI greater than this value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc9c423c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac1c87b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pairplot of all variables by glass type:\n",
    "\n",
    "sns.pairplot(data, hue='Type')\n",
    "plt.suptitle('Pairplot of All Variables by Glass Type', y=1.02)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d6082a1",
   "metadata": {},
   "source": [
    "The pairplot shows the relationships between all pairs of variables, with each point colored by the glass type. Some observations from the pairplot:\n",
    "\n",
    "Glass types 1, 2, and 3 have similar ranges and distributions for most variables, with type 3 having slightly higher magnesium and lower aluminum values.\n",
    "Glass types 5 and 6 have much higher potassium values and lower aluminum and calcium values compared to other types.\n",
    "There is some separation between the types for certain variables, such as refractive index and magnesium content.\n",
    "There are some strong correlations between variables, such as between refractive index and calcium content, and between aluminum and magnesium content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "888a549d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Heatmap\n",
    "corr_matrix = data.corr()\n",
    "sns.heatmap(corr_matrix, cmap='coolwarm', annot=True)\n",
    "plt.title('Heatmap of Correlation Matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86a3e829",
   "metadata": {},
   "source": [
    "The heatmap shows the correlation coefficients between pairs of variables, with darker shades indicating stronger positive or negative correlations. Some observations from the heatmap:\n",
    "\n",
    "Refractive index is strongly positively correlated with calcium content and moderately positively correlated with barium content.\n",
    "Aluminum and magnesium content are strongly negatively correlated.\n",
    "Potassium content is strongly negatively correlated with calcium and barium content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f7cd544",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.boxplot(x='Type', y='RI', data=data)\n",
    "plt.title('Boxplot of Refractive Index by Glass Type')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e0ea0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Observing the Outliers\n",
    "\n",
    "fig, axs = plt.subplots(nrows=3, ncols=4, figsize=(15,10))\n",
    "index = 0\n",
    "for k,v in data.items():\n",
    "    sns.boxplot(y=k, data=data, ax=axs[index//4, index%4])\n",
    "    index += 1\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa42a635",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing outliers\n",
    "\n",
    "Q1 = data.quantile(0.25)\n",
    "Q3 = data.quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "data = data[~((data < (Q1 - 1.5 * IQR)) |(data > (Q3 + 1.5 * IQR))).any(axis=1)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba6443fd",
   "metadata": {},
   "source": [
    "This code removes the outliers from the dataset using the IQR (Interquartile range) method.\n",
    "\n",
    "First, the 25th and 75th percentiles (Q1 and Q3) of each column of the dataset are calculated using the quantile() method.\n",
    "Then, the IQR is calculated as the difference between Q3 and Q1.\n",
    "The outliers are identified as the data points that are below (Q1 - 1.5IQR) or above (Q3 + 1.5IQR) for each column.\n",
    "Finally, the any() method is used to find the rows that contain any outlier in any column, and the ~ operator is used to select the rows that do not have any outliers. These rows are then stored back in the data variable, effectively removing the outliers from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d7f6fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c5cab59",
   "metadata": {},
   "source": [
    "After removing the outlier, the dataset contains 136 observations instead of 214.\n",
    "\n",
    "The mean and standard deviation values for the various features have also changed. For example, the mean value of RI has increased slightly, while the mean value of Mg has increased significantly. The standard deviation values for most features have decreased, indicating that the data points are more tightly clustered around the mean.\n",
    "\n",
    "The maximum value for Ba is now 0, indicating that there are no observations with high Ba values in the dataset after removing the outlier.\n",
    "\n",
    "Overall, the dataset now appears to be more representative of the majority of the glass samples, as the outlier was likely an anomaly that was skewing the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33691181",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for KNN\n",
    "X = data.drop('Type', axis=1)\n",
    "y = data['Type']\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e03f4f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bba774a",
   "metadata": {},
   "source": [
    "# Using Hyperparameter Tuning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2169c80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2344f7ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Fit KNN model and evaluate performance\n",
    "k_values = [1, 3, 5, 7, 9, 11, 13, 15]\n",
    "weights = ['uniform', 'distance']\n",
    "best_accuracy = 0\n",
    "best_k = 0\n",
    "best_weight = ''\n",
    "\n",
    "for k in k_values:\n",
    "    for w in weights:\n",
    "        knn = KNeighborsClassifier(n_neighbors=k, weights=w)\n",
    "        knn.fit(X_train, y_train)\n",
    "        y_pred = knn.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        if accuracy > best_accuracy:\n",
    "            best_accuracy = accuracy\n",
    "            best_k = k\n",
    "            best_weight = w\n",
    "            \n",
    "print(f\"Best accuracy: {best_accuracy:.2f} with k={best_k} and weights='{best_weight}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b3de8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08555bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Create a new instance of KNeighborsClassifier with the best hyperparameters\n",
    "knn = KNeighborsClassifier(n_neighbors=1, weights='uniform')\n",
    "\n",
    "# Fit the model to the training data\n",
    "knn.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2bfa5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# Train KNN with the best hyperparameters\n",
    "knn = KNeighborsClassifier(n_neighbors=1, weights='uniform')\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Calculate confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion matrix:\\n\", cm)\n",
    "\n",
    "# Calculate classification report\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(\"Classification report:\\n\", report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50934840",
   "metadata": {},
   "source": [
    "The KNN model has achieved an accuracy of 78.57% on the glass classification task, which is a relatively good performance. The confusion matrix shows that the model has correctly identified most of the glass types, with only a few misclassifications. The classification report provides a detailed breakdown of the model's performance on each class, including precision, recall, and f1-score. Overall, this is a positive outcome that suggests the KNN model can be used effectively for glass classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b60fc569",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c8a2d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
